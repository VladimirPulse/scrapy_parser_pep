# Проект "Асинхронный парсер PEP"

## Описание проекта
"Асинхронный парсер PEP" — выводит собранную информацию в два файла .csv:
1. В первый файл - список всех PEP: номер, название и статус.
2. Второй файл содержит сводку по статусам PEP — сколько найдено документов в каждом статусе (статус, количество). В последней строке этого файла отражено общее количество всех документов.

## Примененные технологии:
1. SQLAlchemy;
2. Scrapy;
3. Items и Feeds в Scrapy;
4. Pipelines, сохранение в базу данных;

## Инструкция по запуску
1. Перенесите приложение с GitHub себе на комьютер командой `git clone`.
2. Установите виртуальное окружение командой для Windows:`python -m venv venv`, для Linux/macOS:`python3 -m venv venv`. Активируйте виртуальное окружение.
3. Установите необходимые зависимости, запустив команду `pip install -r requirements.txt`.
4. Запуск парсера командой в терминале в корне проекта `scrapy crawl pep`.

## Информация об авторе
Этот проект был разработан Кулаковым В.С., студентом Яндекс-практикума. Вы можете связаться со мной по адресу электронной почты VrachKulakovVS@mail.ru.

