# Проект "Асинхронный парсер PEP"

## Описание проекта
"Асинхронный парсер PEP" — собирает и выводит собранную информацию с сайта `https://peps.python.org/` в два файла формата csv:
1. В первый файл - список всех PEP: номер, название и статус.
2. Второй файл содержит сводку по статусам PEP — сколько найдено документов в каждом статусе (статус, количество). В последней строке этого файла отражено общее количество всех документов.

## Использованные технологии:
1. Python: Основной язык программирования, используемый в этом проекте;
2. Scrapy: Фреймворк для асинхронного парсинга;
2. Pipelines, Items и Feeds в Scrapy для тонкой настройки и обработки полученных данных;
3. Defaultdict: Специальный тип словаря из модуля collections, который использовался для подсчета статусов;
4. CSV: Библиотека для чтения и записи данных в формате CSV, которая была использована для создания выходного файла;
5. Datetime (из модуля datetime): Используется для получения текущей даты и времени для формирования имени;выходного файла.

## Инструкция по запуску
1. Перенесите приложение с GitHub себе на комьютер командой `git clone`.
2. Установите виртуальное окружение командой для Windows:`python -m venv venv`, для Linux/macOS:`python3 -m venv venv`. Активируйте виртуальное окружение.
3. Установите необходимые зависимости, запустив команду `pip install -r requirements.txt`.
4. Запуск парсера командой в терминале в корне проекта `scrapy crawl pep`.

## Информация об авторе
Этот проект был разработан Кулаковым В.С., студентом Яндекс-практикума. Вы можете связаться со мной по адресу электронной почты VrachKulakovVS@mail.ru.
